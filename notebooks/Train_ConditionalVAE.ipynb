{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_ConditionalVAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3uxbPbddh1t"
      },
      "source": [
        "## Check the GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib92JY4KWXBP"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7hwoMBBdync"
      },
      "source": [
        "# Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3TyuDTj-rxN"
      },
      "source": [
        "from google.colab import files\n",
        "# Upload your kaggle.json file with your username and your Kaggle API token.\n",
        "files.upload() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X45MxKFo_FxG"
      },
      "source": [
        "# Let's make sure the kaggle.json file is present. \n",
        "!ls -lha kaggle.json\n",
        "# Next, install the Kaggle API client. \n",
        "!pip install -q kaggle\n",
        "# The Kaggle API client expects this file to be in ~/.kaggle, \n",
        "# so move it there. \n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "# This permissions change avoids a warning on Kaggle tool startup. \n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wwp82A0Assa"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/ConditionalVAE_DL_Project3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZfncmuFA9ho"
      },
      "source": [
        "!python3 dataloader.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHPEAqULod-7"
      },
      "source": [
        "# Build the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWyewtTroc8J"
      },
      "source": [
        "from celeba import CelebADataset\n",
        "\n",
        "# Training configuration\n",
        "learning_rate = 0.001\n",
        "train_size = 0.01\n",
        "batch_size = 32\n",
        "save_test_set = True # S# True: the test set image IDs and other useful information will be stored in a pickle file to further uses (e.g. Image_Generation.ipynb) \n",
        "\n",
        "\n",
        "dataset = CelebADataset(train_size = train_size, batch_size = batch_size, save_test_set = save_test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cck3nhf67ad7"
      },
      "source": [
        "# Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhGfANyK7gyr"
      },
      "source": [
        "# Hyper-parameters\n",
        "label_dim = 40\n",
        "image_dim = [64, 64, 3]\n",
        "latent_dim = 128\n",
        "beta = 0.65\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJcUegj6PT58"
      },
      "source": [
        "import tensorflow as tf\n",
        "from ConvolutionalCondVAE import ConvCVAE, Decoder, Encoder\n",
        "\n",
        "# Model\n",
        "encoder = Encoder(latent_dim)\n",
        "decoder = Decoder()\n",
        "model = ConvCVAE(\n",
        "                encoder,\n",
        "                decoder,\n",
        "                label_dim = label_dim,\n",
        "                latent_dim = latent_dim,\n",
        "                beta = beta,\n",
        "                image_dim = image_dim)\n",
        "\n",
        "# Optiizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2mvjb9jC4Oh"
      },
      "source": [
        "# Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvzfH8T9C6Xj"
      },
      "source": [
        "import os\n",
        "\n",
        "# Checkpoint path\n",
        "checkpoint_root = \"./CVAE{}_{}_checkpoint\".format(latent_dim, beta)\n",
        "checkpoint_name = \"model\"\n",
        "save_prefix = os.path.join(checkpoint_root, checkpoint_name)\n",
        "\n",
        "# Define the checkpoint\n",
        "checkpoint = tf.train.Checkpoint(module=model)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzkw-ICrDQli"
      },
      "source": [
        "# Restore the latest checkpoint\n",
        "latest = tf.train.latest_checkpoint(checkpoint_root)\n",
        "\n",
        "if latest is not None:\n",
        "    checkpoint.restore(latest)\n",
        "    print(\"Checkpoint restored:\", latest)\n",
        "else:\n",
        "  print(\"No checkpoint!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBfn4EZB9z_i"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSxE0asz94X3"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from utils import train_step\n",
        "\n",
        "train_losses = []\n",
        "train_recon_errors = []\n",
        "train_latent_losses = []\n",
        "loss = []\n",
        "reconstruct_loss = []\n",
        "latent_loss = []\n",
        "\n",
        "step_index = 0\n",
        "n_batches = int(dataset.train_size / batch_size)\n",
        "n_epochs = 30\n",
        "\n",
        "print(\"Number of epochs: {},  number of batches: {}\".format(n_epochs, n_batches))\n",
        "\n",
        "# Epochs Loop\n",
        "for epoch in range(5):\n",
        "    start_time = time.perf_counter()\n",
        "    dataset.shuffle() # Shuffling\n",
        "\n",
        "    # Train Step Loop\n",
        "    for step_index, inputs in enumerate(dataset):\n",
        "      total_loss, recon_loss, lat_loss = train_step(inputs, model, optimizer)\n",
        "      train_losses.append(total_loss)\n",
        "      train_recon_errors.append(recon_loss)\n",
        "      train_latent_losses.append(lat_loss)\n",
        "\n",
        "      if step_index + 1 == n_batches:\n",
        "          break\n",
        "\n",
        "    loss.append(np.mean(train_losses, 0))\n",
        "    reconstruct_loss.append(np.mean(train_recon_errors, 0))\n",
        "    latent_loss.append(np.mean(train_latent_losses, 0))\n",
        "\n",
        "    exec_time = time.perf_counter() - start_time\n",
        "    print(\"Execution time: %0.3f \\t Epoch %i: loss %0.4f | reconstr loss %0.4f | latent loss %0.4f\"\n",
        "                        % (exec_time, epoch, loss[epoch], reconstruct_loss[epoch], latent_loss[epoch])) \n",
        "\n",
        "\n",
        "    # Save progress every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "      checkpoint.save(save_prefix + \"_\" + str(epoch + 1))\n",
        "      print(\"Model saved:\", save_prefix)\n",
        "            \n",
        "# Save the final model                \n",
        "checkpoint.save(save_prefix)\n",
        "print(\"Model saved:\", save_prefix)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfl3PjRywq3U"
      },
      "source": [
        "# Loss Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yfbVKF-vY23"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(reconstruct_loss, 'g', marker ='o')\n",
        "plt.grid()\n",
        "plt.show();\n",
        "plt.plot(latent_loss, 'b', marker = 'o')\n",
        "plt.grid()\n",
        "plt.show();\n",
        "plt.plot(loss, 'r', marker ='o')\n",
        "plt.grid()\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
